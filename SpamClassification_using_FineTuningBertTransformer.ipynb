{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMh6X/xVg3WHXabNhC9aqdP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parinita-Jain/Getting-Started-with-NLP/blob/main/SpamClassification_using_FineTuningBertTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "VAi7N0e9pqTU"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "c-fZsCzUpqVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568ecb49-b6c9-414e-bf8e-21e86dbe678c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "bert=BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "from transformers import BertTokenizerFast\n",
        "tokenizer=BertTokenizerFast.from_pretrained(\"bert-base-uncased\",do_lower_case=True)"
      ],
      "metadata": {
        "id": "TV5_K73ipqYT"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "qSf8FTi-ESXb"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"spam.csv\")\n",
        "df.head()\n",
        "df[\"Category\"].value_counts()"
      ],
      "metadata": {
        "id": "paKNol1gndc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d14f66a-e8b6-4d40-9b42-9d6021ab4eea"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "not spam    4825\n",
              "spam         747\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessor(text):\n",
        "  text=text.lower()\n",
        "  text=re.sub(r\"[^a-zA-Z ]+\",\" \",text)\n",
        "  text=re.sub(r\"[\\s]+\",\" \",text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "Wbv9-c9zndet"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Message\"]=df[\"Message\"].apply(preprocessor)\n",
        "text=df[\"Message\"]\n",
        "labels=df[\"Category\"]"
      ],
      "metadata": {
        "id": "oDicp4GSndhQ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "labels=le.fit_transform(labels)"
      ],
      "metadata": {
        "id": "dKj1-WbFndjQ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# library for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# compute no. of words in each tweet\n",
        "num = [len(i.split()) for i in text]\n",
        "\n",
        "plt.hist(num, bins = 30)\n",
        "\n",
        "plt.title(\"Histogram: Length of sentences\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "esMl_9kXH_4Z",
        "outputId": "e4343275-908a-48df-c272-708d94fb6679"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Histogram: Length of sentences')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for i in text:\n",
        "  l.append(len(i.split()))\n",
        "maxlength=int(np.quantile(l,0.95))\n",
        "maxlength"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEhxuQyrHANm",
        "outputId": "49efdef4-2a29-4705-ac9a-d4e87af8f598"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_id=[]\n",
        "for i in range(len(text)):\n",
        "  encoded_sent=tokenizer.encode(text[i],add_special_tokens=True,max_length=maxlength,truncation=True,\n",
        "                                pad_to_max_length=\"right\")\n",
        "  sent_id.append(encoded_sent)"
      ],
      "metadata": {
        "id": "mIi6ZROendmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b015517-0e4e-4204-ccaf-e9233d99cf8c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks=[]\n",
        "for sent in sent_id:\n",
        "  att_mask=[int(token_id>0) for token_id in sent]\n",
        "  attention_masks.append(att_mask)"
      ],
      "metadata": {
        "id": "BxtZ3k2BF4I-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(sent_id, labels, random_state=2018, test_size=0.1, stratify=labels)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size=0.1, stratify=labels)\n",
        ""
      ],
      "metadata": {
        "id": "0X0BOBAYF4LE"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "metadata": {
        "id": "yiPxl8vHF4Op"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        ""
      ],
      "metadata": {
        "id": "44jI6SnzKDQz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create an iterator object\n",
        "iterator = iter(train_dataloader)\n",
        "\n",
        "#loads batch data\n",
        "sent_id, mask, target=next(iterator)\n",
        ""
      ],
      "metadata": {
        "id": "nBu1OgnWKDVR"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pass inputs to the model\n",
        "outputs = bert(sent_id,             #integer sequence\n",
        "               attention_mask=mask, return_dict=False) #attention masks"
      ],
      "metadata": {
        "id": "l3eLWjuNLmiI"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hidden states\n",
        "hidden_states = outputs[0]\n",
        "\n",
        "# [CLS] hidden state\n",
        "CLS_hidden_state = outputs[1]\n",
        "\n",
        "print(\"Shape of Hidden States:\",hidden_states.shape)\n",
        "print(\"Shape of CLS Hidden State:\",CLS_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFz_E35ELmj9",
        "outputId": "b019cb64-0a50-4439-92fe-80bd1d3b46ea"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Hidden States: torch.Size([32, 33, 768])\n",
            "Shape of CLS Hidden State: torch.Size([32, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# turn off the gradient of all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "7KiFofmJLmmR"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#importing nn module\n",
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "\n",
        "    #define the layers and wrappers used by model\n",
        "    def __init__(self, bert):\n",
        "\n",
        "      #constructor\n",
        "      super(classifier, self).__init__()\n",
        "\n",
        "      #bert model\n",
        "      self.bert = bert\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "\n",
        "      #dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "      #relu activation function\n",
        "      self.relu =  nn.Tanh()\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model\n",
        "      all_hidden_states, cls_hidden_state = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "\n",
        "      #pass CLS hidden state to dense layer\n",
        "      x = self.fc1(cls_hidden_state)\n",
        "\n",
        "      #Apply ReLU activation function\n",
        "      x = self.relu(x)\n",
        "\n",
        "      #Apply Dropout\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      #pass input to the output layer\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      #apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "\n",
        "#create the model\n",
        "model = classifier(bert)\n",
        "\n",
        "#push the model to GPU, if available\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "#model architecture\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsuvNAPILmpX",
        "outputId": "97f09701-c829-4c02-e213-1628a42bb5b0"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): Tanh()\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# push the tensors to GPU\n",
        "sent_id = sent_id.to(device)\n",
        "mask = mask.to(device)\n",
        "target = target.to(device)\n",
        "\n",
        "# pass inputs to the model\n",
        "outputs = model(sent_id, mask)"
      ],
      "metadata": {
        "id": "fb5o4gjjF4Rd"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "QVXwWncXMUTB"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#library for array processing\n",
        "import numpy as np\n",
        "\n",
        "#library for computing class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "#class_weights = compute_class_weight('balanced', np.unique(labels), y=labels)\n",
        "class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(labels), y= labels)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cybZvMA2MUVA",
        "outputId": "922a0b2e-85ac-45e0-999e-ec9cad721e98"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [0.57740933 3.72958501]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting a list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# transfer to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)"
      ],
      "metadata": {
        "id": "sk2_mIlPMUYh"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#compute the loss\n",
        "print(target)\n",
        "loss = cross_entropy(outputs, target)\n",
        "print(\"Loss:\",loss)"
      ],
      "metadata": {
        "id": "AGBSfJOCndoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318acd3d-d12c-4d76-ea8a-a8be57b98f29"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
            "Loss: tensor(-0.5001, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "# compute time in hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    # round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds = elapsed_rounded))"
      ],
      "metadata": {
        "id": "jz29aCeWndr1"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function for training the model\n",
        "def train():\n",
        "\n",
        "  print(\"\\nTraining.....\")\n",
        "\n",
        "  #set the model on training phase - Dropout layers are activated\n",
        "  model.train()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds=[]\n",
        "\n",
        "  #for every batch\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "    # Progress update after every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids\n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # Always clear any previously calculated gradients before performing a\n",
        "    # backward pass. PyTorch doesn't do this automatically.\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Perform a forward pass. This returns the model predictions\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    #compute the loss between actual and predicted values\n",
        "    loss =  cross_entropy(preds, labels)\n",
        "\n",
        "    # Accumulate the training loss over all of the batches so that we can\n",
        "    # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "    # single value; the `.item()` function just returns the Python value\n",
        "    # from the tensor.\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # Perform a backward pass to calculate the gradients.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "    # modified based on their gradients, the learning rate, etc.\n",
        "    optimizer.step()\n",
        "\n",
        "    #The model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    #Accumulate the model predictions of each batch\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  #compute the training loss of a epoch\n",
        "  avg_loss     = total_loss / len(train_dataloader)\n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds\n",
        ""
      ],
      "metadata": {
        "id": "8GNr3bFyNs48"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "  print(\"\\nEvaluating.....\")\n",
        "\n",
        "  #set the model on training phase - Dropout layers are deactivated\n",
        "  model.eval()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize the loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  #for each batch\n",
        "  for step,batch in enumerate(validation_dataloader):\n",
        "\n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(validation_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids\n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # Perform a forward pass. This returns the model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      #compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      # Accumulate the validation loss over all of the batches so that we can\n",
        "      # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "      # single value; the `.item()` function just returns the Python value\n",
        "      # from the tensor.\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      #The model predictions are stored on GPU. So, push it to CPU\n",
        "      preds=preds.detach().cpu().numpy()\n",
        "\n",
        "      #Accumulate the model predictions of each batch\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  #compute the validation loss of a epoch\n",
        "  avg_loss = total_loss / len(validation_dataloader)\n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "OKvlS7Y0Ns6m"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assign the initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "#create a empty list to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n....... epoch {:} / {:} .......'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    #accumulate training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2ixf8U5Oolj",
        "outputId": "71fd2ff5-68fa-43c9-cbfa-0752d8b3cfd6"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "....... epoch 1 / 5 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    157.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    157.    Elapsed: 0:00:05.\n",
            "  Batch   120  of    157.    Elapsed: 0:00:07.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: -0.569\n",
            "Validation Loss: -0.706\n",
            "\n",
            "....... epoch 2 / 5 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    157.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    157.    Elapsed: 0:00:05.\n",
            "  Batch   120  of    157.    Elapsed: 0:00:07.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: -0.798\n",
            "Validation Loss: -0.884\n",
            "\n",
            "....... epoch 3 / 5 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    157.    Elapsed: 0:00:03.\n",
            "  Batch    80  of    157.    Elapsed: 0:00:05.\n",
            "  Batch   120  of    157.    Elapsed: 0:00:07.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: -0.851\n",
            "Validation Loss: -0.876\n",
            "\n",
            "....... epoch 4 / 5 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    157.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    157.    Elapsed: 0:00:05.\n",
            "  Batch   120  of    157.    Elapsed: 0:00:07.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: -0.882\n",
            "Validation Loss: -0.845\n",
            "\n",
            "....... epoch 5 / 5 .......\n",
            "\n",
            "Training.....\n",
            "  Batch    40  of    157.    Elapsed: 0:00:02.\n",
            "  Batch    80  of    157.    Elapsed: 0:00:05.\n",
            "  Batch   120  of    157.    Elapsed: 0:00:07.\n",
            "\n",
            "Evaluating.....\n",
            "\n",
            "Training Loss: -0.889\n",
            "Validation Loss: -0.906\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load weights of best model\n",
        "path='saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5exWEyjOonc",
        "outputId": "2a696403-c261-4a4e-ec43-895b3ca3d2ca"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get the model predictions on the validation data\n",
        "# returns 2 elements- Validation loss and Predictions\n",
        "valid_loss, preds = evaluate()\n",
        "print(valid_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDcGTO4eOoqf",
        "outputId": "f02a8711-84e9-4e96-e772-07870e98d7fb"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating.....\n",
            "-0.906277166472541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Converting the log(probabities) into a classes\n",
        "# Choosing index of a maximum value as class\n",
        "y_pred = np.argmax(preds,axis=1)\n",
        "\n",
        "# actual labels\n",
        "y_true = validation_labels\n",
        ""
      ],
      "metadata": {
        "id": "lrYyHyCgNs9A"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "610WRzSRNtAp",
        "outputId": "470b60e4-82f0-4f81-9233-da704f1cf371"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97       483\n",
            "           1       0.82      0.85      0.84        75\n",
            "\n",
            "    accuracy                           0.96       558\n",
            "   macro avg       0.90      0.91      0.91       558\n",
            "weighted avg       0.96      0.96      0.96       558\n",
            "\n"
          ]
        }
      ]
    }
  ]
}